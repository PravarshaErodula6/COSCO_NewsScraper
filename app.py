import streamlit as st
import pandas as pd
import datetime
import plotly.express as px
from wordcloud import WordCloud
import matplotlib.pyplot as plt

# -----------------------------------------------
# ğŸ” Debug Block: Torch and Import Check
# -----------------------------------------------
st.title("ğŸŒ COSCO News Dashboard")

try:
    import torch
    st.success(f"âœ… torch loaded: {torch.__version__}")
except Exception as e:
    st.error(f"âŒ torch import failed: {e}")

try:
    from scraper import run_scraper
    st.success("âœ… scraper.py imported successfully")
except Exception as e:
    st.error(f"âŒ scraper import failed: {e}")

# -----------------------------------------------
# ğŸ› ï¸ Sidebar Controls
# -----------------------------------------------
st.sidebar.title("ğŸ› ï¸ Options")

# âœ… Scrape latest news from all sites
if st.sidebar.button("ğŸ” Scrape Latest News"):
    with st.spinner("Scraping... please wait."):
        try:
            run_scraper()
            st.success("âœ… Scraping complete! Dashboard refreshed.")
        except Exception as e:
            st.error(f"âŒ Scraper failed: {e}")

# ğŸ” Keyword filter
search_keyword = st.sidebar.text_input("Enter keyword to filter articles")

# -----------------------------------------------
# ğŸ—‚ï¸ Load the scraped data
# -----------------------------------------------
@st.cache_data
def load_data():
    import os
    if not os.path.exists("all_sites_summaries3.csv"):
        st.warning("âš ï¸ CSV not found. Click 'Scrape Latest News' to generate it.")
        return pd.DataFrame(columns=["Title", "URL", "Summary", "Site"])
    
    try:
        df = pd.read_csv("all_sites_summaries3.csv")
        df.dropna(subset=["Title", "URL", "Summary"], inplace=True)
        return df
    except Exception as e:
        st.error(f"âŒ Failed to load CSV: {e}")
        return pd.DataFrame(columns=["Title", "URL", "Summary", "Site"])

df = load_data()

# ğŸ” Filter by keyword
if search_keyword:
    df = df[df["Title"].str.contains(search_keyword, case=False) | df["Summary"].str.contains(search_keyword, case=False)]

# âœ… Sort articles by URL
df = df.sort_values(by="URL")

# -----------------------------------------------
# ğŸ“Š Visualizations
# -----------------------------------------------
if not df.empty:
    st.subheader("ğŸ“Š Article Count by Source Site")
    site_counts = df['Site'].value_counts().reset_index()
    site_counts.columns = ['Site', 'Article Count']
    fig = px.bar(site_counts, x='Site', y='Article Count', title="Number of Articles per Site")
    st.plotly_chart(fig, use_container_width=True)

    st.subheader("â˜ï¸ Word Cloud of Article Titles")
    title_text = ' '.join(df['Title'].dropna().tolist())
    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(title_text)
    fig_wc, ax = plt.subplots(figsize=(10, 4))
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.axis("off")
    st.pyplot(fig_wc)

# -----------------------------------------------
# ğŸ“„ Article Summaries
# -----------------------------------------------
if df.empty:
    st.warning("No articles found. Try changing the keyword or scraping again.")
else:
    for row in df.itertuples():
        site_name = row.Site.replace("https://", "").replace("http://", "").replace("www.", "").rstrip("/")
        st.markdown(f"ğŸŒ **Source:** {site_name}")
        st.subheader(row.Title)
        st.markdown(f"[ğŸ”— Read Full Article]({row.URL})", unsafe_allow_html=True)
        st.write(row.Summary)
        st.markdown("---")

# -----------------------------------------------
# â¬‡ï¸ CSV Download Option
# -----------------------------------------------
if not df.empty:
    csv = df.to_csv(index=False).encode('utf-8')
    st.download_button("â¬‡ï¸ Download CSV", csv, "cosco_summaries.csv", "text/csv")

# -----------------------------------------------
# ğŸ§¾ Footer
# -----------------------------------------------
st.markdown("ğŸ› ï¸ Built by **Surya Sanjeeva Pravarsha Erodula** Â· Powered by Python & Streamlit")
